# ğŸ¤– Assistente de Livraria com LLM

Este projeto backend em Python demonstra como integrar um Large Language Model (LLM) gratuito para criar um assistente de atendimento ao cliente contextualizado para uma livraria online.

## âœ¨ Funcionalidades

* **Resposta Contextualizada**: O LLM responde como um assistente de livraria ğŸ“š.
* **IntegraÃ§Ã£o com LLM**: Conecta-se Ã  API de InferÃªncia do Hugging Face para gerar respostas ğŸ’¬.
* **SeguranÃ§a com `.env`**: Suas chaves de API ficam seguras e fora do repositÃ³rio pÃºblico ğŸ”’.
